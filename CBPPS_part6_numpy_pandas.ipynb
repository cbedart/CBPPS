{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtzOLKX+r2yxVC8bd6mEMl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbedart/CBPPS/blob/2024/CBPPS_part6_numpy_pandas.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<h1><center>Part 6 - NumPy and Pandas</center></h1>**"
      ],
      "metadata": {
        "id": "2UbbMu31uZAq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Iv6FgdiYufFm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **➤ NumPy**\n",
        "\n",
        "- The NumPy module is a must-have for performing calculations on vectors or matrices, element by element, via a new object type called `Array`.\n",
        "- Unlike the modules seen last week, NumPy is not supplied with the basic Python distribution. You can install it with one of the commands:\n",
        "\n",
        "```\n",
        "pip install numpy\n",
        "OR\n",
        "conda install -c conda-forge numpy\n",
        "```\n",
        "- To load the NumPy module, you have to put on your code `import numpy`\n",
        "- By convention, we use `np` as a short name for NumPy = `import numpy as np`\n",
        "\n",
        "- NumPy official user guide is great = https://numpy.org/doc/stable/user/\n",
        "- A good cheat sheet = https://assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf"
      ],
      "metadata": {
        "id": "1ZjwJe5utL9L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "dir(np)"
      ],
      "metadata": {
        "id": "AZo_juFZlWMI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Array objects**\n",
        "\n",
        "- Correspond to one- or multi-dimensional arrays\n",
        "- Can be used to perform vector calculations\n",
        "- Function `array()` to convert a \"container\" (a list or a tuple, as an example) into an array object\n",
        "- Python will use the word array and `([`  `])` symbols to distinguish it from a list `[]` or a tuple `()` (... but print will format the array as a list of elements)\n",
        "- Everything we saw with lists and tuples also applies to arrays"
      ],
      "metadata": {
        "id": "wYg_joNKldRg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "list1 = [\"hazelnuts\", \"apples\", \"oranges\", \"pears\"]\n",
        "\n",
        "array1 = np.array(list1)\n",
        "array1"
      ],
      "metadata": {
        "id": "FyrdUc0gmPuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1[1]"
      ],
      "metadata": {
        "id": "fymKELUwqmmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(range(5))"
      ],
      "metadata": {
        "id": "U4_AFhdZnWjG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- An array object contains only homogeneous data = Only one identical type\n",
        "- It is possible to create an array object from a list containing integers and strings, but in this case, all values will be understood by NumPy as strings:"
      ],
      "metadata": {
        "id": "SD1DnadZoASh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list2 = [\"ruler\", 14.368, \"disk\", 12]\n",
        "\n",
        "np.array(list2)"
      ],
      "metadata": {
        "id": "Vmnr-1uCkfK2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Similarly, it is possible to create an array object from a list of integers and floats, but all values will then be understood by NumPy as only integers (if no float in the elements) or only floats (if at least one float in the elements)"
      ],
      "metadata": {
        "id": "BSE7gGjMoLG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list3 = [12, 54, 29]\n",
        "\n",
        "np.array(list3)"
      ],
      "metadata": {
        "id": "b-DOf_MeoTvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list4 = [12.5, 54, 29]\n",
        "\n",
        "np.array(list4)"
      ],
      "metadata": {
        "id": "iaPgsuW5oYre"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Uses and functions identical to Python base (sometimes even improved)**\n",
        "\n",
        "- `np.arange()` can create a 1-dimension array, as `range()`\n",
        "- Generate array objects with not only integers, **but floats too** !\n",
        "- The `np.concatenate((arrayX, arrayY), axis=0)` must be used if you want to concatenate arrays, since you can't use the + symbol anymore\n",
        "    - If arrayX and arrayY are 1D, you can only use a tuple of arrays\n",
        "    - If arrayX and arrayY are 2D, you need to add the `axis` argument to tell NumPy whether to concatenate along axis 0 (rows - default) or axis 1 (columns), if only the dimensions are compatible"
      ],
      "metadata": {
        "id": "B9H0MRIGoptI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(10)"
      ],
      "metadata": {
        "id": "s8_eeBc4pEkS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(0, 10, 2)"
      ],
      "metadata": {
        "id": "YzGZeljEpGcw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(10.0)"
      ],
      "metadata": {
        "id": "rgitCd9WpTRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.arange(0, 10, 0.2)"
      ],
      "metadata": {
        "id": "7JkRUG1-pVTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array1 = np.array(['hazelnuts', 'apples', 'oranges', 'pears'])\n",
        "array2 = np.array([1,2,3,4,5])\n",
        "array3 = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "array4 = np.array([[1, 2, 2], [3, 4, 5], [5, 6, 0]])"
      ],
      "metadata": {
        "id": "8cAftr9z3gD7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array1, array2))"
      ],
      "metadata": {
        "id": "1hzUu7xo3J7Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array2, array1))"
      ],
      "metadata": {
        "id": "OsqYEmIr3M9_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array3, array1))"
      ],
      "metadata": {
        "id": "ImQnbod32l5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array3, array4), axis = 0)"
      ],
      "metadata": {
        "id": "wXxJKGQy3Sag"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array3, array4), axis = 1)"
      ],
      "metadata": {
        "id": "9qsp_oN-3Xo3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array3, array3), axis = 0)"
      ],
      "metadata": {
        "id": "-m5pMYE13xym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.concatenate((array3, array3), axis = 1)"
      ],
      "metadata": {
        "id": "hiFfAth43wk7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "/!\\ An array is considered as a **vector** /!\\\\\n",
        "\n",
        "- Element-by-element vector operations can be performed on this type of object\n",
        "- All operations are not performed on the “list” or “tuple” element, but on each element from the \"array\" individually.\n",
        "- Very useful when analyzing large quantities of data\n",
        "- Since every single operation is performed on each element, you can easily conditions to get a new array element with `True` or `False` depending on each value"
      ],
      "metadata": {
        "id": "TPEJlwkhpZ7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array2 = np.array([1, 2, 3, 4, 5])\n",
        "array2"
      ],
      "metadata": {
        "id": "L6TCCiXjpZKQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array2 + 1"
      ],
      "metadata": {
        "id": "p288QYeSptaV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array2 * 5"
      ],
      "metadata": {
        "id": "OWjKxstLpuPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array2 * array2"
      ],
      "metadata": {
        "id": "PgL6XJEWpxJ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array2 > 2"
      ],
      "metadata": {
        "id": "jNEZAnQt52wF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3 = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "array3 > 2"
      ],
      "metadata": {
        "id": "xEZQzJWZ56BI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It is also possible to build 2-dimensional array objects by passing a list of lists as arguments to the array() function\n",
        "- Same as 3D, with list of list of lists\n",
        "- etc.\n",
        "- In 2D, organized as tables with rows (1st index) and then columns (2nd index)"
      ],
      "metadata": {
        "id": "fby36ze_p_k4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array3 = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "array3"
      ],
      "metadata": {
        "id": "wpAVRzIdqX3y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3[1][0]"
      ],
      "metadata": {
        "id": "mK-uvxMBq48O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4 = np.array([[[1, 2], [2, 3]], [[4, 5], [5, 6]]])\n",
        "array4"
      ],
      "metadata": {
        "id": "ShdQyF3Kp_SY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Some useful attributes:**\n",
        "\n",
        "- `arrayX.ndim` returns the number of array dimensions\n",
        "- `arrayX.shape` returns the dimensions as a tuple. In the case of a matrix (2D array), the first value of the tuple corresponds to the number of rows, and the second to the number of columns\n",
        "- `arrayX.size` returns the total number of elements contained in the array\n",
        "\n"
      ],
      "metadata": {
        "id": "AqDy3p8BrDvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array4.ndim"
      ],
      "metadata": {
        "id": "yQahnG7ArfjR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.shape"
      ],
      "metadata": {
        "id": "7-4Qaetzrg7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.size"
      ],
      "metadata": {
        "id": "CkDkzR-srikL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### **Some useful functions:**\n",
        "\n",
        "- `np.zeros((X,Y))` to generate a 2D array (a matrix) of X rows and Y columns with only 0\n",
        "- `np.ones((X,Y))` same with only 1\n",
        "- `np.full(value, (X,Y), type)` same with only the value of the selected type"
      ],
      "metadata": {
        "id": "Tdvuwfvo1N8c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.zeros((2, 3))"
      ],
      "metadata": {
        "id": "kUzGOxh01Nqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.ones((3, 3))"
      ],
      "metadata": {
        "id": "-PO-KEht1No1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.full((2, 3), 7, int)"
      ],
      "metadata": {
        "id": "MjnzGkgB1oIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.full((2, 3), 7, float)"
      ],
      "metadata": {
        "id": "_FaLzdlI1o4f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `np.transpose(arrayX)` to transpose the matrix, the same as `arrayX.T`\n",
        "- `np.dot(arrayX, arrayY)` to get matrix product between two matrices (since `arrayX * arrayY` returns the product element by element.)\n",
        "- `np.diag(arrayX)` with an array to diagonalize the matrix, or `np.diag([X,Y,Z])` with a list/tuple to get a diagonal matrix with the chosen numeric values\n",
        "- etc."
      ],
      "metadata": {
        "id": "7991OZgC3-cp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array4 = np.array([[1, 2, 2], [3, 4, 5], [5, 6, 0]])\n",
        "\n",
        "np.transpose(array4)"
      ],
      "metadata": {
        "id": "garOkTjX35bQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.dot(array4, array4)"
      ],
      "metadata": {
        "id": "4nyXI9Ad4i6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4 * array4"
      ],
      "metadata": {
        "id": "ejTetFEL40BL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.diag(array4)"
      ],
      "metadata": {
        "id": "58Rvgzdi4_PI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.diag([1,2,3])"
      ],
      "metadata": {
        "id": "YHbqQt5T5L16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `np.loadtxt()` to load a numeric data file already organized as rows and columns\n",
        "- `np.savetxt()` to save a numeric data file organized as rows and columns\n",
        "- BUT:\n",
        "    - Each row must have the same number of columns = the function does not handle missing data\n",
        "    - Each data item is converted to a float, so if a string is encountered the function returns an error\n",
        "    - By default, data must be separated by any combination of space(s) and/or tabs"
      ],
      "metadata": {
        "id": "mviteNUa19VD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Some useful methods:**\n",
        "\n",
        "- `arrayX.reshape((X,Y))` returns a new array with the dimensions specified in the argument, **BUT** will not modify arrayX in place\n",
        "    - (4,2) is totally different from (2,4)\n",
        "    - (X,Y) is a tuple containing the new dimensions, and **must** be compatible with the initial dimensions of the array\n",
        "    - That **will NOT change** the value of the `arrayX` variable\n",
        "- `arrayX.resize((X,Y))`, on the other hand, doesn't trigger an error in such a situation if the refcheck argument is False as `refcheck=False`, and :\n",
        "    - If there are fewer dimensions = Cut the array up to the last selected value\n",
        "    - If there are more dimensions = Fill with 0\n",
        "    - That **will change** the value of the `arrayX` variable\n",
        "- `np.resize(arrayX, (X,Y))` will, in the case of a new array larger than the initial one, repeat the initial array in order to fill in the missing cells:\n",
        "    - That **will NOT change** the value of the `arrayX` variable"
      ],
      "metadata": {
        "id": "ZNvYBGy7ru4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array4 = np.array([[[1, 2], [2, 3]], [[4, 5], [5, 6]]])"
      ],
      "metadata": {
        "id": "QAmAXZCoyv0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.reshape((4,2))"
      ],
      "metadata": {
        "id": "5pfWIImSxfn_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.reshape((2,4))"
      ],
      "metadata": {
        "id": "4-8ArJ02xkEW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.reshape((2,2))\n",
        "array4"
      ],
      "metadata": {
        "id": "qFbXal2lxlEB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.resize((3,3))\n",
        "array4"
      ],
      "metadata": {
        "id": "tcRHzFC3zMdg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array4.resize((3,3), refcheck=False)\n",
        "array4"
      ],
      "metadata": {
        "id": "xQ4qGgR9yLKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.resize(array4, (2,2))\n",
        "array4"
      ],
      "metadata": {
        "id": "4SxN1Lh_z2vX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Indices**\n",
        "\n",
        "- To retrieve one or more elements from an array object, you can use indices, in the same way as with lists\n",
        "- Slices and steps can also be used\n",
        "- The syntax `a[i, j]` is used to compress the retrieval of the element in row i, then column j, into a single block. You can combine with slices to get one full row/column, as `a[i, :]`\n",
        "- You also can use a boolean matrix, generated with a condition as an example, to easily filter your array based on this condition"
      ],
      "metadata": {
        "id": "BnptmS940QC7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "array3 = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "array3"
      ],
      "metadata": {
        "id": "lXT2RhfR0xqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3[0:2]"
      ],
      "metadata": {
        "id": "8l-EeJzr074_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3[0,1]"
      ],
      "metadata": {
        "id": "FawsEKRi0_4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3[:,1]"
      ],
      "metadata": {
        "id": "XwPrvCjn1HiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3 > 3"
      ],
      "metadata": {
        "id": "PJfAOrFZ6Khl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "array3[array3 > 3]"
      ],
      "metadata": {
        "id": "QkYPvCy36LVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br />\n",
        "\n",
        "---   "
      ],
      "metadata": {
        "id": "4cA-flM9w-mU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **➤ Pandas**\n",
        "\n",
        "- The Pandas module has been designed for data analysis\n",
        "- Particularly powerful for manipulating structured data in tabular form\n",
        "- One of the modules that you will probably use the most in your codes\n",
        "- You can install it with one of the commands:\n",
        "```\n",
        "pip install pandas\n",
        "OR\n",
        "conda install -c conda-forge pandas\n",
        "```\n",
        "- To load the Pandas module, you have to put on your code `import pandas`\n",
        "- By convention, we use `pd` as a short name for Pandas = `import pandas as pd`\n",
        "\n",
        "<br />\n",
        "\n",
        "- The **HUGE** difference with NumPy is Pandas will also indices, but will also assign a key to each element in each dimension (= row names, column names, etc.)\n",
        "    - Very similar to the dictionaries within a dictionary seen before\n",
        "    - Data manipulation is therefore much easier using just the names of the assigned rows and columns\n",
        "    - If no labels are assigned, the key will automatically the same as the indices\n",
        "- Moreover, Pandas is perfectly integrated with Jupyter Notebooks, so Google Colab too, to provide easy-to-use representations\n",
        "\n",
        "<br />\n",
        "\n",
        "- The Pandas user guide is incredible = https://pandas.pydata.org/docs/user_guide/index.html\n",
        "- A good cheat sheet from the official website = https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf\n"
      ],
      "metadata": {
        "id": "HVsOhjbl6WUl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "dir(pd)"
      ],
      "metadata": {
        "id": "_bmIWsum6xm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Series**\n",
        "\n",
        "- Correspond to 1-dimension vector array (X rows but only 1 column)\n",
        "- Created with `pd.Series(list/tuple/np.array/etc.)`\n",
        "- You can attribute custom keys with the `index` argument (optional)\n",
        "- Everything works like NumPy's 1D arrays"
      ],
      "metadata": {
        "id": "qr_BoTk97xsN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series([1,2,3])"
      ],
      "metadata": {
        "id": "91qTaen07PCc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series1 = pd.Series([1,2,3], index = [\"Laptop\", \"Hazelnut\", \"Robert\"])\n",
        "series1"
      ],
      "metadata": {
        "id": "jnSdq4p19p4P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series1 * 2"
      ],
      "metadata": {
        "id": "__QUyHJy9oTr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- With Pandas, each element in the data series has a label that can be used to call the elements\n",
        "- You can also use the `.loc[]` \"strange method\", as there is no `()` but `[]` since we want to locate elements\n",
        "- To call the first element in the series, you can use its key (here, “Laptop”):\n"
      ],
      "metadata": {
        "id": "K3q2Ps7h96-j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series1[\"Laptop\"]"
      ],
      "metadata": {
        "id": "1NGOwGX3-HUo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series1.loc[\"Laptop\"]"
      ],
      "metadata": {
        "id": "FQ3U7Bk1ARwq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- But you can also use the classical index location with the `.iloc[X]` \"strange method\", as again there is no `()` but `[]` since we want to locate elements"
      ],
      "metadata": {
        "id": "dCssjbV8-Z2C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series1.iloc[1]"
      ],
      "metadata": {
        "id": "gM2adqHV-fLe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can extract multiple elements by giving a list of keys or a list of indices"
      ],
      "metadata": {
        "id": "i_743imj--GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series1[[\"Laptop\", \"Hazelnut\"]]"
      ],
      "metadata": {
        "id": "4IXii4iO_Dx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series1.iloc[[0,1]]"
      ],
      "metadata": {
        "id": "WIsxifVy_Fm9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- All Series operations work like dictionaries, using new keys to attribute new values, etc.\n"
      ],
      "metadata": {
        "id": "Swn_bEpO_KOL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series1"
      ],
      "metadata": {
        "id": "bcjtOu5v_3Yw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "series1[\"Glasses\"] = 98\n",
        "series1"
      ],
      "metadata": {
        "id": "8XlySiBD_36A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "/!\\ A Series is ALSO considered as a vector, as the NumPy arrays. Reminder: /!\\\n",
        "\n",
        "- Element-by-element vector operations can be performed on this type of object\n",
        "- All operations are not performed on the “list” or “tuple” element, but on each element from the \"array\" individually.\n",
        "- Since every single operation is performed on each element, you can easily conditions to get a new array element with True or False depending on each value"
      ],
      "metadata": {
        "id": "D9PHWeOF_2nm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "series1[series1 > 5]"
      ],
      "metadata": {
        "id": "wQzuxduX_-Ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Dataframe**\n",
        "\n",
        "- Pandas main event (and the closest to R tables)\n",
        "- Two-dimensional tables with row and column labels as keys\n",
        "- Created with `pd.DataFrame(list of lists/dictionary of dictionaries/2D NumPy array/etc.)`\n",
        "- You can use the `columns` argument to give columns names, and `index` to give row names - Must be the same dimension\n",
        "- If you need to change later the columns or index keys, you can use the method `dataframeX.columns` or `dataframeX.index`\n",
        "- Everything works like NumPy's 2D arrays"
      ],
      "metadata": {
        "id": "y7G_gnUoAckF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([[1,2,3],[1,2,3]])"
      ],
      "metadata": {
        "id": "UiO72NgXAcBK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([[1,2,3],[1,2,3]], columns=[\"a\",\"b\",\"c\"])"
      ],
      "metadata": {
        "id": "AwOMZxKjBaeN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame([[1,2,3],[1,2,3]], columns=[\"a\",\"b\",\"c\"], index=[\"x\",\"y\"])"
      ],
      "metadata": {
        "id": "GV0h6_rQBrVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({\"x\":{\"a\":1, \"b\":2, \"c\":3}, \"y\":{\"a\":1, \"b\":2, \"c\":3}})"
      ],
      "metadata": {
        "id": "kn_knIoCBIzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = pd.DataFrame({\"x\":[1,2,30], \"y\":[4,50,6]}, index=[\"a\",\"b\",\"c\"])\n",
        "df1"
      ],
      "metadata": {
        "id": "7phLvlCJCEMe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.columns = [\"X\", \"Y\"]\n",
        "df1"
      ],
      "metadata": {
        "id": "i8H6_Xh4CY6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.index = [\"Robert\", \"Hazelnuts\", \"Laptop\"]\n",
        "df1"
      ],
      "metadata": {
        "id": "VrDfx-g8CfFJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"Z\"] = [99, 1586, 10000]\n",
        "df1"
      ],
      "metadata": {
        "id": "HUNQsRyrThCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[\"Ruler\"] = [12, 12, 12]\n",
        "df1"
      ],
      "metadata": {
        "id": "PhzEwQQSToBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Some properties**\n",
        "\n",
        "- `dataframeX.columns` and `dataframeX.index` to get the columns and index keys (seen just before)\n",
        "- `dataframeX.shape` to get the dimensions of the DataFrame\n",
        "- `dataframeX.head(n)` to only get the first n rows of the DataFrame\n",
        "- `dataframeX.info()` to get more information about your DataFrame, as counts, variable types, etc.\n",
        "- `dataframeX.isna()` to know if there is some missing value"
      ],
      "metadata": {
        "id": "qBu6VV9aCmoS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = pd.DataFrame({\"Species\":[\"Iris\",\"Iris\",\"Poppy\",\"Poppy\",\"Iris\"], \"Length\":[5,7,10,15,9], \"Width\":[10,12,5,6,17]})\n",
        "df2"
      ],
      "metadata": {
        "id": "v7iYL3cTOzrw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.shape"
      ],
      "metadata": {
        "id": "5GcIfF-4C_Ew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.head(2)"
      ],
      "metadata": {
        "id": "ASJwNVw8DCAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.info()"
      ],
      "metadata": {
        "id": "mcwLXamPNESz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.isna()"
      ],
      "metadata": {
        "id": "JXG2Bj3qNWzE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Mathematical/Statistical operators**\n",
        "\n",
        "- `dataframeX.describe()` to get really fast a LOT of descriptive statistics for each column, or to use in combination with `[]` or `.loc[]`\n",
        "- `dataframeX.value_counts()` to get the value counts for each column, or one line\n",
        "- `dataframeX[\"X\"].mean()` or `dataframeX.loc[\"X\"].mean()` to get the mean of a column or a row (or multiple if you give lists)\n",
        "    - Same using `.min()`, `.max()`, `.std()`, `.median()`, `.sum()`, etc.\n",
        "    - Same using `.unique()` to only get the unique values"
      ],
      "metadata": {
        "id": "OhRYl5q6NOZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dir(df2[\"Width\"])"
      ],
      "metadata": {
        "id": "sSl9_OclQPhb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.describe()"
      ],
      "metadata": {
        "id": "HcXIk-mJNw3d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"Width\"].describe()"
      ],
      "metadata": {
        "id": "dfJczvX8Nmqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2[\"Species\"].value_counts()"
      ],
      "metadata": {
        "id": "4O4NonB7N_9E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `df2.groupby(\"X\")` to group rows based on the column with the key \"X\" and used as new row keys, but to be used with another operator to indicate how the data will be merged:\n",
        "    - `df2.groupby(\"X\").sum()` to compute the sum\n",
        "    - `df2.groupby(\"X\").min()` to keep the minimum value\n",
        "    - `df2.groupby(\"X\").max()` to keep the maximum value\n",
        "    - `df2.groupby(\"X\").mean()` to compute the mean\n",
        "    - etc."
      ],
      "metadata": {
        "id": "T-cquCJAPgr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2.groupby(\"Species\")"
      ],
      "metadata": {
        "id": "g0MojRSnOyX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2.groupby(\"Species\").mean()"
      ],
      "metadata": {
        "id": "yH6veUAERaSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Select, filter, manipulate data from a DataFrame**\n"
      ],
      "metadata": {
        "id": "Hlm6Dva3DGzA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selection mechanisms featured in pandas are very powerful:\n",
        "- **Columns selection:**\n",
        "    - You can select a column using its key => Series object\n",
        "    - You can select multiple columns using a list of keys, in order of provided keys => DataFrame object"
      ],
      "metadata": {
        "id": "pgMoiU6cDP4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"X\"]"
      ],
      "metadata": {
        "id": "gOupkFzBDbpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[[\"Y\",\"X\"]]"
      ],
      "metadata": {
        "id": "cwi6c8dPDk0w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Rows selection**:\n",
        "    - Since the columns is the default, you must use `.loc[]` instead of only `[]` to get the rows, either a key or a list of keys"
      ],
      "metadata": {
        "id": "GN6vPVCWD69I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[\"Robert\"]"
      ],
      "metadata": {
        "id": "ZxmPyr0WEM1w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[[\"Laptop\", \"Robert\"]]"
      ],
      "metadata": {
        "id": "ewaM9uWyEOdP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Columns AND rows selection**:\n",
        "    - But you can use multiple arguments in the `.loc[]` to get rows AND columns, as `.loc[x,y]`\n",
        "    - To use the same as `[]`, you must select every single row with the `:` symbol, as `.loc[:,y]`\n",
        "    - And again, you can use lists of keys"
      ],
      "metadata": {
        "id": "i_lV3fc_EmPE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[\"Robert\",\"X\"]"
      ],
      "metadata": {
        "id": "AFp_IHGcERoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[:,\"X\"]"
      ],
      "metadata": {
        "id": "Gmvk4QbaETE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.loc[[\"Laptop\", \"Robert\"], [\"Y\",\"X\"]]"
      ],
      "metadata": {
        "id": "x6DCpo36E1QI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Condition selection**:\n",
        "    - As NumPy arrays and Pandas Series, you can use conditions (or list/dataframes of booleans) in place of keys\n",
        "    - You can combine conditions with `[]` or `.loc[]`\n",
        "    - You can also combine several conditions with `&` for the `and` operator and `|` for the `or` operator, with `()` around each condition"
      ],
      "metadata": {
        "id": "ASxa92EvE5l2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df1[\"X\"]>10"
      ],
      "metadata": {
        "id": "dqxGUeW6GCUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[df1[\"X\"]>10]"
      ],
      "metadata": {
        "id": "Nw8Y4iIcE5Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[df1[\"X\"]>10][\"Y\"]"
      ],
      "metadata": {
        "id": "KEIOndPoGoq_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[(df1[\"X\"]>10) & (df1[\"Y\"]< 10)]"
      ],
      "metadata": {
        "id": "bHpDU7wYHL_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1[(df1[\"X\"]>10) & (df1[\"Y\"]< 5)]"
      ],
      "metadata": {
        "id": "uRM-bgABHWJL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Combination of dataframes**\n",
        "\n",
        "- `pd.concat([df1, df2])` will combine a list of dataframes\n",
        "- `NaN` = Not a Number, if there is missing values\n",
        "- By default, will only paste the dataframes one below the others\n",
        "- The `axis` argument is used to merge existing rows (`axis=0` - default) or columns (`axis=1`)\n",
        "- The `join` argument is used to specify whether to keep only data common to both dataframes (`join=\"inner\"`) or keep everything (`join=\"outer\"` - default)"
      ],
      "metadata": {
        "id": "c8HLu7RqHa6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data1 = {\"Lyon\": [10, 23, 17], \"Paris\": [3, 15, 20]}\n",
        "data1_df = pd.DataFrame.from_dict(data1)\n",
        "data1_df.index = [\"Shop\", \"Restaurant\", \"Bakery\"]\n",
        "\n",
        "data2 = {\"Nantes\": [3, 9, 14], \"Strasbourg\": [5, 10, 8]}\n",
        "data2_df = pd.DataFrame.from_dict(data2)\n",
        "data2_df.index = [\"Shop\", \"Pharmacy\", \"Fastfood\"]"
      ],
      "metadata": {
        "id": "yQvcM4k4HfTj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([data1_df, data2_df])"
      ],
      "metadata": {
        "id": "vbuaMrz1IUMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([data1_df, data2_df], axis = 0)"
      ],
      "metadata": {
        "id": "zJuyBmeCI3rv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([data1_df, data2_df], axis = 1)"
      ],
      "metadata": {
        "id": "JByk1mzjIx2u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.concat([data1_df, data2_df], axis = 1, join = \"inner\")"
      ],
      "metadata": {
        "id": "CyVYrcqJJcE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Files manipulation**\n",
        "\n",
        "Pandas includes a wide range of functions for reading and writing files of different types\n",
        "- `pd.read_csv(\"file.csv\")` (or `pd.read_table(\"file.csv\")`) & `dataframeX.to_csv(\"file.csv\")`\n",
        "    - The most important one, X-separated values as comma (csv) or tab (tsv)-separated values files, or just plain text files (txt) separated with spaces\n",
        "    - The `sep` argument is used to give the separator string, as `sep=\",\"`,  `sep=\"\\t\"`, or `sep=\" \"`\n",
        "    - The `header` argument to tell Python if there is a column names line or not in your file using None or the column index, as `header=None` or `header=3` - Default = row with index 0\n",
        "    - Same using `index_col` when reading or `index` when writing, to tell Python if there is a row names column or not in your file using None or the row index, as `index_col=None` when reading or `index=0` when writing - Default = column with index 0"
      ],
      "metadata": {
        "id": "PFpkCJdPJtdl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/cbedart/CBPPS/raw/refs/heads/2024/IMDb_dataset.tsv > /dev/null 2>&1\n",
        "!mkdir imdb ; mv IMDb_dataset.tsv imdb/IMDb_dataset.tsv\n",
        "\n",
        "imdb = pd.read_csv(\"imdb/IMDb_dataset.tsv\", sep=\"\\t\")\n",
        "imdb"
      ],
      "metadata": {
        "id": "yIfm3MCHKDeC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdb.to_csv(\"imdb.txt\", sep=\"µ\", header=None, index=None)"
      ],
      "metadata": {
        "id": "wM_XPke4JtOh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- `pd.read_excel(\"file.xlsx\")` & `dataframeX.to_excel(\"file.xlsx\")` to read/save as excel files\n",
        "- `pd.read_pickle(\"file.pkl\")` & `dataframeX.to_pickle(\"file.pkl\")` to read/save as highly-compressed binary file named pickle. Can be used to store huge amounts of data in a very limited space\n",
        "- `pd.read_json(\"file.json\")` & `dataframeX.to_json(\"file.json\")` to read/write JSON files\n",
        "- etc."
      ],
      "metadata": {
        "id": "FO5HRw_VR60Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br />\n",
        "\n",
        "---   "
      ],
      "metadata": {
        "id": "uZTHshdBYjbp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**➤ Exercises :**\n"
      ],
      "metadata": {
        "id": "BAPvtv5c-hxb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Exercise 1 - Use case in data analysis... but sounds familiar:</u>** You are going to study some data from IMDb, a website that lists movies and series and lets users rate them.\n",
        "\n",
        "- By launching the first block below, you will download the file `IMDb_dataset.tsv` under the path `/content/imdb/IMDb_dataset.tsv` (you can click on this link after running the block to see the file in a new window on the right).\n",
        "- This is a `tab-separated value` text file, where all the fields in a line are separated by a tab `\\t`.\n",
        "- All movies are considered to be longer than 60 minutes, and all series shorter than 60 minutes.\n",
        "\n",
        "<br />\n",
        "\n",
        "From the data in this file:\n",
        "\n",
        "1. Read the file, and transform it into a more suitable format, using what you've seen so far, so you can use it easily.\n",
        "2. What is the average score for all the movies, and for all the series?\n",
        "3. What is the most common recommended audience categories for all these productions?\n",
        "4. How many productions were created in 1998? In 2002? In 2015?\n",
        "5. Calculate a new variable dividing the number of votes by the rating awarded. Which production is the most successful, with the highest score in relation to the number of votes? And the least one?\n",
        "6. Search your data for information on \"Arcane\", the best series ever created, by displaying its score and the number of voters using `print()` and an f-string. Generalize your code with a function to give the information for any row in the dataset if it exists, otherwise say that the name is not in the list."
      ],
      "metadata": {
        "id": "jgQLPvyhIamx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### RUN BEFORE YOUR EXERCISE 1 #####\n",
        "\n",
        "!wget https://github.com/cbedart/CBPPS/raw/refs/heads/2024/IMDb_dataset.tsv > /dev/null 2>&1\n",
        "!mkdir imdb ; mv IMDb_dataset.tsv imdb/IMDb_dataset.tsv\n",
        "\n",
        "######################################"
      ],
      "metadata": {
        "id": "4NB2UyQLIZwe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1 - #1\n",
        "# Read the file, and transform it into a more suitable format, using what you've seen so far, so you can use it easily.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qqw7PrONNL5D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1 - #2\n",
        "# What is the average score for all the movies, and for all the series?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TD7QkDfGOSC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1 - #3\n",
        "# What is the most common recommended audience categories for all these productions?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0BAY9gV2OSiO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1 - #4\n",
        "# How many productions were created in 1998? In 2002? In 2015?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KJNF7J6fOSt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1 - #5\n",
        "# Calculate a new variable dividing the number of votes by the rating awarded. Which production is the most successful, with\n",
        "# the highest score in relation to the number of voters? And the least one?\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5RPP_cDcOS-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 1 - #6\n",
        "# Search your data for information on \"Arcane\", the best series ever created, by displaying its score and the number of voters\n",
        "# using print() and an f-string. Generalise your code to give the information for any row in the dataset if it exists, otherwise\n",
        "# say that the name is not in the list.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8SAIZC-iOTUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Exercise 2 - Evolution of the COVID-19 pandemic in France:</u>**\n",
        "\n",
        "You will study the summary of indicators tracking the COVID-19 epidemic in France, by French departments, from January 23, 2020 to June 30, 2023, using the `/content/covid.csv` file\n",
        "- You will find all the information in the header of the data gouv website (in French), but you can easily use DeepL or Google Translate on the webpage/Data description part to get the most important information\n",
        "- https://www.data.gouv.fr/fr/datasets/synthese-des-indicateurs-de-suivi-de-lepidemie-covid-19/\n",
        "\n",
        "<br />\n",
        "\n",
        "From the data in this file:\n",
        "1. Load the file, and use clear and meaningful names for each column instead of the abbreviations.\n",
        "2. How many French departments and regions are there in this document?\n",
        "3. In which department and on which day was there the greatest peak in current hospitalizations and new hospitalizations?\n",
        "4. Filter your DataFrame to only keep the numbers for the \"Nord\" department.\n",
        "    - When did we reach our highest positivity, incidence, and occupancy rates?\n",
        "    - How many total hospitalizations and deaths were caused by COVID in the department during the epidemic?\n",
        "    - What was the average number of new hospitalizations per year in 2020, 2021, 2022, and 2023?\n",
        "5. Group all departments together to obtain data for the whole country.\n",
        "    - When did we reach our highest virus replication R, positivity, incidence, and occupancy T0 rates?\n",
        "    - How many total hospitalizations and deaths were caused by COVID in the country during the epidemic?\n",
        "    - What was the average number of new hospitalizations per year in 2020, 2021, 2022, and 2023?\n",
        "6. Split the date using the `dataframeX[\"date\"].str.split(\"-\", expand=True)` function, to get a new dataframe with the year, the month, and the day in 3 columns.\n",
        "    - Add to your big dataframes (all departments and France) the year, month and day in 3 different columns with clear and meaningful names.\n",
        "    - Using a loop, iterate over each month of your files to create two new monthly dataframe (department and France), to identify the number of new hospitalizations and deaths per month, as well as the average virus replication R, positivity, incidence, and occupancy T0 rates over the time periods.\n",
        "7. Using a function taking as input the name of a department and a year, automate an output (with `return dataframeX`)to give monthly statistics for the department in question compared with the whole of France as the simplest DataFrame (PS: It's a must to use existing parts of your code, to generalize what you have done.)."
      ],
      "metadata": {
        "id": "P8d9vAX_Uhr-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##### RUN BEFORE YOUR EXERCISE 2 #####\n",
        "\n",
        "!wget https://www.data.gouv.fr/fr/datasets/r/5c4e1452-3850-4b59-b11c-3dd51d7fb8b5 > /dev/null 2>&1\n",
        "!mv 5c4e1452-3850-4b59-b11c-3dd51d7fb8b5 covid.csv\n",
        "\n",
        "######################################"
      ],
      "metadata": {
        "id": "-IQFw9kyUj5d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #1\n",
        "# Load the file, and use clear and meaningful names for each column instead of the abbreviations.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "6-mW6bJ8W8qq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #2\n",
        "# How many French departments and regions are there in this document?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pFghDim-X_Pk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #3\n",
        "# In which department and on which day was there the greatest peak in current hospitalizations and new hospitalizations?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rhnGNTWldzr4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #4\n",
        "# Filter your DataFrame to only keep the numbers for the \"Nord\" department.\n",
        "#   - When did we reach our highest positivity, incidence, and occupancy rates?\n",
        "#   - How many total hospitalizations and deaths were caused by COVID in the department during the epidemic?\n",
        "#   - What was the average number of new hospitalizations per year in 2020, 2021, 2022, and 2023?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0mRl0C9Td2xU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #5\n",
        "# Group all departments together to obtain data for the whole country.\n",
        "#   - When did we reach our highest virus replication R, positivity, incidence, and occupancy T0 rates?\n",
        "#   - How many total hospitalizations and deaths were caused by COVID in the country during the epidemic?\n",
        "#   - What was the average number of new hospitalizations per year in 2020, 2021, 2022, and 2023?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5m8H30LAeH7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #6\n",
        "# Split the date using the dataframeX[\"date\"].str.split(\"-\", expand=True) function, to get a new dataframe with the year, the month, and the day in 3 columns.\n",
        "#   - Add to your big dataframes (all departments and France) the year, month and day in 3 different columns with clear and meaningful names.\n",
        "#   - Using a loop, iterate over each month of your files to create two new monthly dataframe (department and France), to identify the number of new hospitalizations\n",
        "#       and deaths per month, as well as the average virus replication R, positivity, incidence, and occupancy T0 rates over the time periods\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "tv5-7XxRePXC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 2 - #7\n",
        "# Using a function taking as input the name of a department and a year, automate an output (with `return dataframeX`)\n",
        "# to give monthly statistics for the department in question compared with the whole of France as the simplest DataFrame.\n",
        "# (PS: It's a must to use existing parts of your code, to generalize what you have done.).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "hEaYVYQsePnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**<u>Exercise 3 - As you want:</u>**\n",
        "\n",
        "If you have time at the end, you can try to analyze some of your research files using Pandas and/or NumPy."
      ],
      "metadata": {
        "id": "bV3gr_G1e5U9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Exercise 3\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EMU5dAiafNY6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}